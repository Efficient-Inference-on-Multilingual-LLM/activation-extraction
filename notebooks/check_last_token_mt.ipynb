{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510a6038",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "import math\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9965ad9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_path = 'prompts/mt/prompt_en.txt'\n",
    "os.path.basename(prompt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a69f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target Language: Indonesia (3), English (5)\n",
    "# Source Language: Hindi Latin (4), French (5), Javanese (1), Sundanese (1), Turkish (4), Welsh (1)\n",
    "\n",
    "# Target Language: ind_Latn, eng_Latn\n",
    "# Source Language: -, fra_Latn, jav_Latn, sun_Latn, tur_Latn, cym_Latn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a773dd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5689a758",
   "metadata": {},
   "outputs": [],
   "source": [
    "langs = ['ind_Latn', 'eng_Latn', 'fra_Latn', 'jav_Latn', 'sun_Latn', 'tur_Latn', 'cym_Latn']\n",
    "target_langs = ['ind_Latn', 'eng_Latn']\n",
    "source_langs = ['fra_Latn', 'jav_Latn', 'sun_Latn', 'tur_Latn', 'cym_Latn']\n",
    "languages_name = {\n",
    "    'ind_Latn': 'Indonesian',\n",
    "    'eng_Latn': 'English',\n",
    "    'fra_Latn': 'French',\n",
    "    'jav_Latn': 'Javanese',\n",
    "    'sun_Latn': 'Sundanese',\n",
    "    'tur_Latn': 'Turkish',\n",
    "    'cym_Latn': 'Welsh'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016dcfaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "datasets_per_lang = {}\n",
    "for lang in langs:\n",
    "    datasets_per_lang[lang] = load_dataset(\"openlanguagedata/flores_plus\", lang, split=\"devtest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6b5749",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_per_lang['ind_Latn'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a48811f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_en = \"\"\"Translate the following text from {source_lang} to {target_lang}.\n",
    "Text: {text}\n",
    "Translated Text:\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55daf1fb",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e23ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models\n",
    "# LLama 3.2 1B\n",
    "# Gemma 3 1B\n",
    "# Sahabat-AI/gemma2-9b-cpt-sahabatai-v1-instruct\n",
    "# Sahabat-AI/llama3-8b-cpt-sahabatai-v1-instruct\n",
    "# bigscience/bloom-7b1\n",
    "# sail/Sailor2-8B-Chat\n",
    "# Qwen/Qwen3-8B\n",
    "# CohereLabs/aya-expanse-8b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab80346",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'CohereLabs/aya-expanse-8b'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=\"auto\", device_map=\"cuda\")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3c0465",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_hooked_model(initial_dataset, source_lang: str, target_lang: str, languages_name: dict, model, tokenizer, model_name: str, initial_prompt: str = None, prompt_lang: str = None, save_results: bool = False, is_base_model: bool = False\t):\n",
    "\tresults = {}\n",
    "\tdataset = deepcopy(initial_dataset)\n",
    "\tif initial_prompt:\n",
    "\t\tprint(f\"Saving to outputs_1token_mt/{model_name}/prompt_{prompt_lang}/{source_lang}-{target_lang}\")\n",
    "\telse:\n",
    "\t\tprint(f\"Saving to outputs_1token_mt/{model_name}/prompt_raw/{lang}\")\n",
    "\tfor test_instance in tqdm(dataset):\n",
    "\t\t# prepare the model input\n",
    "\t\tif initial_prompt:\n",
    "\t\t\tsave_dir = f'outputs_1token_mt/{model_name}/prompt_{prompt_lang}/{source_lang}-{target_lang}/{test_instance['id']}'\n",
    "\t\t\tprompt = initial_prompt.replace(\"{text}\", test_instance['text'])\n",
    "\t\t\tprompt = prompt.replace(\"{source_lang}\", languages_name[source_lang])\n",
    "\t\t\tprompt = prompt.replace(\"{target_lang}\", languages_name[target_lang])\n",
    "\t\t\tif is_base_model:\n",
    "\t\t\t\ttext = prompt\n",
    "\t\t\telse: # if using a chat/instruct model\n",
    "\t\t\t\tmessages = [\n",
    "\t\t\t\t\t{\"role\": \"user\", \"content\": prompt}\n",
    "\t\t\t\t]\n",
    "\t\telse:\n",
    "\t\t\tsave_dir = f'outputs_1token_mt/{model_name}/prompt_raw/{source_lang}-{target_lang}/{test_instance['id']}'\n",
    "\t\t\tif is_base_model:\n",
    "\t\t\t\ttext = test_instance['text']\n",
    "\t\t\telse: # if using a chat/instruct model\n",
    "\t\t\t\tmessages = [\n",
    "\t\t\t\t\t{\"role\": \"user\", \"content\": deepcopy(test_instance['text'])}\n",
    "\t\t\t\t]\n",
    "\t\tif not is_base_model:\n",
    "\t\t\tif 'bloom' not in model_name:\n",
    "\t\t\t\ttext = tokenizer.apply_chat_template(\n",
    "\t\t\t\t\tmessages,\n",
    "\t\t\t\t\ttokenize=False,\n",
    "\t\t\t\t\tadd_generation_prompt=True,\n",
    "\t\t\t\t\tenable_thinking=False # Switches between thinking and non-thinking modes. Default is True.\n",
    "\t\t\t\t)\n",
    "\t\t\telse:\n",
    "\t\t\t\ttext = messages[0]['content']\n",
    "\t\tmodel_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "\t\tdef hook_fn(m, i, o, layer_id):\n",
    "\t\t\tos.makedirs(save_dir, exist_ok=True)\n",
    "\t\t\tsave_path = os.path.join(save_dir, f\"{layer_id}.pt\")\n",
    "\t\t\t# Fix (i guess because of the transformers version, it is not nested anymore)\n",
    "\t\t\t# torch.save(o[0][0, -1, :].detach().cpu(), save_path)\n",
    "\t\t\t# o: [batch_size, sequence_length, hidden_dimension]\n",
    "\t\t\ttorch.save(o[0, -1, :].detach().cpu(), save_path)\n",
    "\t\t\t\n",
    "\t\tif 'bloom' in model_name:\n",
    "\t\t\tfor i, layer in enumerate(model.transformer.h):\n",
    "\t\t\t\tlayer.register_forward_hook(\n",
    "\t\t\t\t\tlambda m, i, o, layer_id=i: hook_fn(m, i, o, layer_id=layer_id)\n",
    "\t\t\t\t)\n",
    "\t\telse:\n",
    "\t\t\tfor i, layer in enumerate(model.model.layers):\n",
    "\t\t\t\tlayer.register_forward_hook(\n",
    "\t\t\t\t\tlambda m, i, o, layer_id=i: hook_fn(m, i, o, layer_id=layer_id)\n",
    "\t\t\t\t)\n",
    "\n",
    "\t\t# conduct text completion\n",
    "\t\tgenerated_ids = model.generate(\n",
    "\t\t\t**model_inputs,\n",
    "\t\t\tmax_new_tokens=1\n",
    "\t\t)\n",
    "\t\t\n",
    "\t\toutput_ids = generated_ids[0][len(model_inputs.input_ids[0]):].tolist()\n",
    "\t\tcontent = tokenizer.decode(output_ids, skip_special_tokens=True)\n",
    "\t\tresults[test_instance['id']] = content\n",
    "\n",
    "\t\t# Clear hooks after processing\n",
    "\t\tif 'bloom' in model_name:\n",
    "\t\t\tfor layer in model.transformer.h:\n",
    "\t\t\t\tfor hook in layer._forward_hooks.values():\n",
    "\t\t\t\t\tlayer._forward_hooks.clear()\n",
    "\t\telse:\n",
    "\t\t\tfor layer in model.model.layers:\n",
    "\t\t\t\tfor hook in layer._forward_hooks.values():\n",
    "\t\t\t\t\tlayer._forward_hooks.clear()\n",
    "\tif save_results:\t\t\t\n",
    "\t\treturn results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4289dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Processing with english prompt.')\n",
    "for target_lang in target_langs:\n",
    "    for source_lang in source_langs:\n",
    "        print(\"Processing source language:\", source_lang, \"and target language:\", target_lang)\n",
    "        results = inference_hooked_model(\n",
    "            initial_dataset=datasets_per_lang[source_lang],\n",
    "            source_lang=source_lang,\n",
    "\t\t\ttarget_lang=target_lang,\n",
    "            languages_name=languages_name,\n",
    "\t\t\tmodel=model,\n",
    "\t\t\ttokenizer=tokenizer,\n",
    "\t\t\tmodel_name=model_name.split('/')[-1],\n",
    "\t\t\tinitial_prompt=prompt_en,\n",
    "\t\t\tprompt_lang='en',\n",
    "\t\t\tsave_results=True,\n",
    "\t\t\tis_base_model=False\n",
    "\t\t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17141619",
   "metadata": {},
   "source": [
    "## Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e97fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "language_pairs = []\n",
    "for target_lang in target_langs:\n",
    "\tfor source_lang in source_langs:\n",
    "\t\tlanguage_pairs.append(f\"{source_lang}-{target_lang}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c086897",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_per_lang['fra_Latn'].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b35f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_by_category(dataset_dict: dict, model_name: str, num_layers: int, labels: list, language_pairs: list, outputs_dir: str = 'outputs_1token_mt', prompt_lang: str = 'en', save_plot: bool = False, save_plot_indicator: str = 'topics', show_plot: bool = True, save_tsne: bool = False, calculate_tsne: bool = True):\n",
    "\tdataset_sample = dataset_dict['fra_Latn'].to_pandas()\n",
    "\tcmap = plt.get_cmap('tab10')\n",
    "\tcolor_map = {category: cmap(i) for i, category in enumerate(labels)}\n",
    "\tfig, axes = plt.subplots(math.ceil(num_layers/7), 7, figsize=(50, 5 * math.ceil(num_layers/7)))\n",
    "\taxes = axes.flatten()\n",
    "\t\n",
    "\tfor layer in range(num_layers):\n",
    "\t\t# Load the activation for the current layer for all samples\n",
    "\t\tactivation_np = []\n",
    "\t\tcategories_or_langs = []  # Store either categories or language_pairs\n",
    "\t\t# Iterate through the dataset and load activations\n",
    "\t\tif calculate_tsne:\n",
    "\t\t\tfor idx, row in dataset_sample.iterrows():\n",
    "\t\t\t\tfor lang_pair in language_pairs:\n",
    "\t\t\t\t\tactivation_path = f'{outputs_dir}/{model_name}/prompt_{prompt_lang}/{lang_pair}/{row['id']}/{layer}.pt'\n",
    "\t\t\t\t\tactivation = torch.load(activation_path)\n",
    "\t\t\t\t\tactivation = activation.float()\n",
    "\t\t\t\t\tactivation_np.append(activation.cpu().numpy())\n",
    "\t\t\t\t\tif 'lang-pairs' in save_plot_indicator:\n",
    "\t\t\t\t\t\tcategories_or_langs.append(lang_pair)\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\traise ValueError(\"Invalid save_plot_indicator. Use 'lang-pairs'.\")\n",
    "\t\t\t\n",
    "\t\t\tactivation_np = np.array(activation_np)\n",
    "\t\t\n",
    "\t\t\t# Perform t-SNE with 2 components\n",
    "\t\t\ttsne = TSNE(n_components=2, random_state=42, n_jobs=-1)\n",
    "\t\t\tactivation_2d = tsne.fit_transform(activation_np)\n",
    "\t\telse:\n",
    "\t\t\t# Read precomputed t-SNE results\n",
    "\t\t\ttsne_path = f'{outputs_dir}/{model_name}/tsne/prompt_{prompt_lang}/layer-{layer}_tsne_{save_plot_indicator}.npy'\n",
    "\t\t\tif os.path.exists(tsne_path):\n",
    "\t\t\t\tactivation_2d = np.load(tsne_path)\n",
    "\t\t\telse:\n",
    "\t\t\t\traise FileNotFoundError(f\"Precomputed t-SNE results not found at {tsne_path}. Set calculate_tsne to True to compute t-SNE.\")\n",
    "\t\t\t\n",
    "\t\t\t# Load metadata (categories or languages)\n",
    "\t\t\tmetadata_path = f'{outputs_dir}/{model_name}/tsne/prompt_{prompt_lang}/layer-{layer}_metadata_{save_plot_indicator}.pkl'\n",
    "\t\t\tif os.path.exists(metadata_path):\n",
    "\t\t\t\twith open(metadata_path, 'rb') as f:\n",
    "\t\t\t\t\tcategories_or_langs = pickle.load(f)\n",
    "\t\t\telse:\n",
    "\t\t\t\traise FileNotFoundError(f\"Metadata not found at {metadata_path}. Set calculate_tsne to True to compute t-SNE.\")\n",
    "\t\t\n",
    "\t\t# Save t-SNE results if requested\n",
    "\t\tif save_tsne:\n",
    "\t\t\ttsne_dir = f'{outputs_dir}/{model_name}/tsne/prompt_{prompt_lang}'\n",
    "\t\t\tos.makedirs(tsne_dir, exist_ok=True)\n",
    "\t\t\t\n",
    "\t\t\t# Save t-SNE coordinates\n",
    "\t\t\ttsne_save_path = os.path.join(tsne_dir, f'layer-{layer}_tsne_{save_plot_indicator}.npy')\n",
    "\t\t\tnp.save(tsne_save_path, activation_2d)\n",
    "\t\t\t\n",
    "\t\t\t# Save metadata (categories or languages) to a pickle file\n",
    "\t\t\tmetadata_save_path = os.path.join(tsne_dir, f'layer-{layer}_metadata_{save_plot_indicator}.pkl')\n",
    "\t\t\twith open(metadata_save_path, 'wb') as f:\n",
    "\t\t\t\tpickle.dump(categories_or_langs, f)\n",
    "\n",
    "\t\t\tprint(f\"Saved t-SNE results for layer {layer} to {tsne_dir}\")\n",
    "\n",
    "\t\t# Plot the t-SNE results (activation_2d), with colors based on the predicted category or language\n",
    "\t\tax = axes[layer]\n",
    "\t\tax.set_title(f'Layer {layer + 1}')\n",
    "\t\t\n",
    "\t\t# Create scatter plot for each label to enable legend\n",
    "\t\tfor label in labels:\n",
    "\t\t\tmask = [cat_or_lang == label for cat_or_lang in categories_or_langs]\n",
    "\t\t\tif any(mask):\n",
    "\t\t\t\tax.scatter(activation_2d[mask, 0], activation_2d[mask, 1], \n",
    "\t\t\t\t\t\tc=color_map[label], s=10, alpha=0.5, label=label)\n",
    "\t\t\n",
    "\t\tax.set_xlabel('t-SNE Component 1')\n",
    "\t\tax.set_ylabel('t-SNE Component 2')\n",
    "\t\tax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=8)\n",
    "\t\n",
    "\t# Save the plot if required\n",
    "\tif save_plot:\n",
    "\t\tos.makedirs(f'{outputs_dir}/{model_name}/plots/prompt_{prompt_lang}', exist_ok=True)\n",
    "\t\tplt.savefig(f'{outputs_dir}/{model_name}/plots/prompt_{prompt_lang}/tsne_{save_plot_indicator}.png', bbox_inches='tight')\n",
    "\n",
    "\tif show_plot:\n",
    "\t\tplt.tight_layout()\n",
    "\t\tplt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04fdeb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2e725e",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_langs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e9362b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot per target lang\n",
    "for target_lang in target_langs:\n",
    "\tplot_by_category(\n",
    "\t\tdataset_dict=datasets_per_lang, \n",
    "\t\tmodel_name=model_name.split('/')[-1],\n",
    "\t\tnum_layers=len(model.transformer.h) if 'bloom' in model_name else len(model.model.layers),\n",
    "\t\tlabels=[lang_pair for lang_pair in language_pairs if target_lang in lang_pair],\n",
    "\t\tlanguage_pairs=[lang_pair for lang_pair in language_pairs if target_lang in lang_pair],\n",
    "\t\toutputs_dir='outputs_1token_mt',\n",
    "\t\tprompt_lang='en',\n",
    "\t\tsave_plot=True,\n",
    "\t\tsave_plot_indicator=f'lang-pairs_{target_lang}',\n",
    "\t\tshow_plot=False,\n",
    "\t\tsave_tsne=True,\n",
    "\t\tcalculate_tsne=True\n",
    "\t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064488e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot merged ind and eng\n",
    "plot_by_category(\n",
    "\tdataset_dict=datasets_per_lang, \n",
    "\tmodel_name=model_name.split('/')[-1],\n",
    "\tnum_layers=len(model.transformer.h) if 'bloom' in model_name else len(model.model.layers),\n",
    "\tlabels=language_pairs,\n",
    "\tlanguage_pairs=language_pairs,\n",
    "\toutputs_dir='outputs_1token_mt',\n",
    "\tprompt_lang='en',\n",
    "\tsave_plot=True,\n",
    "\tsave_plot_indicator=f'lang-pairs_merged',\n",
    "\tshow_plot=False,\n",
    "\tsave_tsne=True,\n",
    "\tcalculate_tsne=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7205d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_lang = 'ind_Latn'\n",
    "plot_by_category(\n",
    "\tdataset_dict=datasets_per_lang, \n",
    "\tmodel_name=model_name.split('/')[-1],\n",
    "\tnum_layers=len(model.transformer.h) if 'bloom' in model_name else len(model.model.layers),\n",
    "\tlabels=[lang_pair for lang_pair in language_pairs if target_lang in lang_pair],\n",
    "\tlanguage_pairs=[lang_pair for lang_pair in language_pairs if target_lang in lang_pair],\n",
    "\toutputs_dir='outputs_1token_mt',\n",
    "\tprompt_lang='en',\n",
    "\tsave_plot=True,\n",
    "\tsave_plot_indicator=f'lang-pairs_{target_lang}',\n",
    "\tshow_plot=False,\n",
    "\tsave_tsne=True,\n",
    "\tcalculate_tsne=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c48a894",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_lang = 'eng_Latn'\n",
    "plot_by_category(\n",
    "\tdataset_dict=datasets_per_lang, \n",
    "\tmodel_name=model_name.split('/')[-1],\n",
    "\tnum_layers=len(model.transformer.h) if 'bloom' in model_name else len(model.model.layers),\n",
    "\tlabels=[lang_pair for lang_pair in language_pairs if target_lang in lang_pair],\n",
    "\tlanguage_pairs=[lang_pair for lang_pair in language_pairs if target_lang in lang_pair],\n",
    "\toutputs_dir='outputs_1token_mt',\n",
    "\tprompt_lang='en',\n",
    "\tsave_plot=True,\n",
    "\tsave_plot_indicator=f'lang-pairs_{target_lang}',\n",
    "\tshow_plot=False,\n",
    "\tsave_tsne=True,\n",
    "\tcalculate_tsne=True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev-lf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
