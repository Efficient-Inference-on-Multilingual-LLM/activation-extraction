{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c80bd5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "097ed320",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from dotenv import load_dotenv\n",
    "from datasets import load_dataset, concatenate_datasets\n",
    "from tqdm import tqdm\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c783b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseActivationSaver:\n",
    "\t\"\"\"\n",
    "\tBase class for saving activations from different models.\n",
    "\t\"\"\"\n",
    "\tdef __init__(self, base_save_dir: str, task_id: str, data_split: str, model_name: str, prompt_id: str):\n",
    "\t\tself.task_id = task_id\n",
    "\t\tself.data_split = data_split\n",
    "\t\tself.model_name = model_name\n",
    "\t\tself.prompt_id = prompt_id\n",
    "\t\tself.base_save_dir = base_save_dir\n",
    "\t\tself.current_id = None\n",
    "\t\tself.current_lang = None\n",
    "\n",
    "\tdef set_id(self, new_id):\n",
    "\t\tself.current_id = new_id\n",
    "\n",
    "\tdef set_lang(self, new_lang):\n",
    "\t\tself.current_lang = new_lang\n",
    "\n",
    "\tdef hook_fn(self, module, input, output, layer_id):\n",
    "\t\traise NotImplementedError(\"This method should be overridden by subclasses.\")\n",
    "\n",
    "\tdef pre_hook_fn(self, module, input, layer_id):\n",
    "\t\traise NotImplementedError(\"This method should be overridden by subclasses.\")\n",
    "\n",
    "\t# Check if activations for an instance already exist\n",
    "\tdef check_exists(self):\n",
    "\t\tpath_last_token = os.path.join(self.base_save_dir, self.task_id, self.data_split, self.model_name.split('/')[-1], self.prompt_id, self.current_lang, self.current_id, \"last_token\")\n",
    "\t\tpath_average = os.path.join(self.base_save_dir, self.task_id, self.data_split, self.model_name.split('/')[-1], self.prompt_id, self.current_lang, self.current_id, \"average\")\n",
    "\t\tcheck_files = os.listdir(path_last_token) if os.path.exists(path_last_token) else []\n",
    "\n",
    "\t\t# # Check if each extraction exist\n",
    "\t\t# post_attn_files = [f for f in check_files if 'postattn' in f]\n",
    "\t\t# post_mlp_files = [f for f in check_files if 'postmlp' in f]\n",
    "\t\t# embed_token_file = [f for f in check_files if 'embed_tokens' in f]\n",
    "\t\t# if len(post_attn_files) == 0 or len(post_mlp_files) == 0 or len(embed_token_file) == 0:\n",
    "\t\t# \treturn False\n",
    "\t\t\n",
    "\t\t# Check average directory files\n",
    "\t\tcheck_files_avg = os.listdir(path_average) if os.path.exists(path_average) else []\n",
    "\n",
    "\t\t# If there are any files, return True\n",
    "\t\treturn bool(check_files) and bool(check_files_avg)\n",
    "\n",
    "\tdef _save_activation_last_token(self, tensor, layer_id):\n",
    "\t\tpath = os.path.join(self.base_save_dir, self.task_id, self.data_split, self.model_name.split('/')[-1], self.prompt_id, self.current_lang, self.current_id, \"last_token\")\n",
    "\t\tos.makedirs(path, exist_ok=True)\n",
    "\t\tsave_path = os.path.join(path, f\"layer_{layer_id}.pt\")\n",
    "\t\ttorch.save(tensor[0, -1, :].detach().cpu(), save_path)\n",
    "\n",
    "\tdef _save_activation_average(self, tensor, layer_id):\n",
    "\t\tpath = os.path.join(self.base_save_dir, self.task_id, self.data_split, self.model_name.split('/')[-1], self.prompt_id, self.current_lang, self.current_id, \"average\")\n",
    "\t\tos.makedirs(path, exist_ok=True)\n",
    "\t\tsave_path = os.path.join(path, f\"layer_{layer_id}.pt\")\n",
    "\t\ttorch.save(tensor[0].mean(dim=0).detach().cpu(), save_path)\n",
    "\t\n",
    "\tdef _check_set_id_lang(self, layer_id):\n",
    "\t\tif self.current_id is None:\n",
    "\t\t\tprint(f\"Warning: ID not set for layer {layer_id}\")\n",
    "\t\t\treturn False\n",
    "\n",
    "\t\tif self.current_lang is None:\n",
    "\t\t\tprint(f\"Warning: Language not set for layer {layer_id}\")\n",
    "\t\t\treturn False\n",
    "\t\t\n",
    "\t\treturn True\n",
    "\t\n",
    "class GeneralActivationSaver(BaseActivationSaver): # Handle Gemma3, Qwen, Pythia, Llama, Aya101 (T5) models (models that activation are returned in form of a tuple)\n",
    "\n",
    "\tdef hook_fn(self, module, input, output, layer_id):\n",
    "\t\tif self._check_set_id_lang(layer_id) is False:\n",
    "\t\t\treturn\n",
    "\t\ttry:\n",
    "\t\t\tself._save_activation_last_token(tensor=output[0] if isinstance(output, tuple) else output, layer_id=layer_id) # Unpack tensor from the tuple\n",
    "\t\t\tself._save_activation_average(tensor=output[0] if isinstance(output, tuple) else output, layer_id=layer_id)\n",
    "\t\texcept Exception as e:\n",
    "\t\t\tprint(f\"Error in hook_fn for layer {layer_id}: {e}\")\n",
    "\t\n",
    "\tdef pre_hook_fn(self, module, input, layer_id):\n",
    "\t\tif self._check_set_id_lang(layer_id) is False:\n",
    "\t\t\treturn\n",
    "\n",
    "\t\ttry:\n",
    "\t\t\t# Extract residual connection after attention (precisely after post-attention layer norm)\n",
    "\t\t\tself._save_activation_last_token(tensor=input[0] if isinstance(input, tuple) else input, layer_id=layer_id)\n",
    "\t\t\tself._save_activation_average(tensor=input[0] if isinstance(input, tuple) else input, layer_id=layer_id)\n",
    "\t\texcept Exception as e:\n",
    "\t\t\tprint(f\"Error in pre_hook_fn for layer {layer_id}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2773cd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseHookedModel:\n",
    "\t\"\"\"\n",
    "\tBase class for hooking into different models.\n",
    "\t\"\"\"\n",
    "\tdef __init__(self, model_name: str, saver: BaseActivationSaver):\n",
    "\t\tdevice = \"cpu\"\n",
    "\t\tmodel_dtype = torch.float16\n",
    "\t\tif torch.cuda.is_available():\n",
    "\t\t\tdevice = \"cuda\"\n",
    "\t\t\tcompute_capability = torch.cuda.get_device_capability()[0]\n",
    "\n",
    "\t\t\t# Use bfloat16 if supported\n",
    "\t\t\tif compute_capability >= 8:\n",
    "\t\t\t\tmodel_dtype = torch.bfloat16\n",
    "\t\t\n",
    "\t\tself.model_name = model_name\n",
    "\t\tself.saver = saver\n",
    "\t\tself.model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=model_dtype, device_map=device, cache_dir=os.getenv(\"HF_CACHE_DIR\"))\n",
    "\t\tself.model.eval()\n",
    "\t\n",
    "\tdef _setup_hooks(self):\n",
    "\t\traise NotImplementedError(\"This method should be overridden by subclasses.\")\n",
    "\t\n",
    "\tdef set_saver_id(self, new_id: int):\n",
    "\t\tself.saver.set_id(new_id)\n",
    "\n",
    "\tdef set_saver_lang(self, new_lang: str):\n",
    "\t\tself.saver.set_lang(new_lang)\n",
    "\t\t\n",
    "\tdef generate(self, inputs):\n",
    "\t\twith torch.no_grad():\n",
    "\t\t\toutputs = self.model.generate(\n",
    "\t\t\t\t**inputs,\n",
    "\t\t\t\tmax_new_tokens=1,\n",
    "\t\t\t)\n",
    "\t\treturn outputs\n",
    "\n",
    "\t# Clear hooks for debugging purposes\n",
    "\tdef clear_hooks(self):\n",
    "\t\tif 'bloom' in self.model_name:\n",
    "\t\t\tfor i, layer in enumerate(self.model.transformer.h):\n",
    "\t\t\t\tlayer._forward_hooks.clear()\n",
    "\t\telse:\n",
    "\t\t\tself.model.model.embed_tokens._forward_hooks.clear()\n",
    "\t\t\tself.model.model.norm._forward_hooks.clear()\n",
    "\t\t\tfor i, layer in enumerate(self.model.model.layers):\n",
    "\t\t\t\tlayer._forward_hooks.clear()\n",
    "\t\t\t\tlayer._forward_pre_hooks.clear()\n",
    "\t\t\t\t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8bee987",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseHookedSeq2SeqModel:\n",
    "\t\"\"\"\n",
    "\tBase class for hooking into different seq2seq models.\n",
    "\t\"\"\"\n",
    "\tdef __init__(self, model_name: str, saver: BaseActivationSaver):\n",
    "\t\tdevice = \"cpu\"\n",
    "\t\tmodel_dtype = torch.float16\n",
    "\t\tif torch.cuda.is_available():\n",
    "\t\t\tdevice = \"cuda\"\n",
    "\t\t\tcompute_capability = torch.cuda.get_device_capability()[0]\n",
    "\n",
    "\t\t\t# Use bfloat16 if supported\n",
    "\t\t\tif compute_capability >= 8:\n",
    "\t\t\t\tmodel_dtype = torch.bfloat16\n",
    "\t\t\n",
    "\t\tself.model_name = model_name\n",
    "\t\tself.saver = saver\n",
    "\t\tself.model = AutoModelForSeq2SeqLM.from_pretrained(model_name, torch_dtype=model_dtype, device_map=device, cache_dir=os.getenv(\"HF_CACHE_DIR\"))\n",
    "\t\tself.model.eval()\n",
    "\n",
    "\tdef _setup_hooks(self):\n",
    "\t\traise NotImplementedError(\"This method should be overridden by subclasses.\")\n",
    "\t\n",
    "\tdef set_saver_id(self, new_id: int):\n",
    "\t\tself.saver.set_id(new_id)\n",
    "\n",
    "\tdef set_saver_lang(self, new_lang: str):\n",
    "\t\tself.saver.set_lang(new_lang)\n",
    "\t\t\n",
    "\tdef generate(self, inputs):\n",
    "\t\twith torch.no_grad():\n",
    "\t\t\toutputs = self.model.generate(\n",
    "\t\t\t\t**inputs,\n",
    "\t\t\t\tmax_new_tokens=1,\n",
    "\t\t\t)\n",
    "\t\treturn \n",
    "\n",
    "class T5HookedModel(BaseHookedSeq2SeqModel):\n",
    "\t\"\"\"\n",
    "\tHooked model for T5 architecture.\n",
    "\t\"\"\"\n",
    "\tdef __init__(self, model_name: str, saver: BaseActivationSaver):\n",
    "\t\tsuper().__init__(model_name, saver)\n",
    "\t\tself._setup_hooks()\n",
    "\t\t\n",
    "\tdef _setup_hooks(self):\n",
    "\t\t# Hook embedding layer\n",
    "\t\tself.model.decoder.embed_tokens.register_forward_hook(\n",
    "\t\t\tlambda module, input, output: self.saver.hook_fn(module, input, output, layer_id=\"embed_tokens\")\n",
    "\t\t)\n",
    "\n",
    "\t\tfor i, block in enumerate(self.model.decoder.block):\n",
    "\t\t\t# Self-attention residual\n",
    "\t\t\tblock.layer[0].register_forward_hook(lambda module, input, output, layer_id=f\"residual-postselfattn_{i}\": self.saver.hook_fn(module, input, output, layer_id=layer_id))\n",
    "\t\t\t\n",
    "\t\t\t# Cross-attention residual\n",
    "\t\t\tblock.layer[1].register_forward_hook(lambda module, input, output, layer_id=f\"residual-postcrossattn_{i}\": self.saver.hook_fn(module, input, output, layer_id=layer_id))\n",
    "\t\t\t\n",
    "\t\t\t# MLP residual\n",
    "\t\t\tblock.layer[2].register_forward_hook(lambda module, input, output, layer_id=f\"residual-postmlp_{i}\": self.saver.hook_fn(module, input, output, layer_id=layer_id))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d502bf1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
     ]
    }
   ],
   "source": [
    "# login huggingface\n",
    "from huggingface_hub import login\n",
    "login(token=os.getenv(\"HF_TOKEN\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6a499e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"CohereLabs/aya-101\"\n",
    "# model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.bfloat16, device_map=\"cuda\", cache_dir=os.getenv(\"HF_CACHE_DIR\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f8fe39e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CohereLabs/aya-101'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa30e10a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16083123ab354269b92eea5980430551",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, BitsAndBytesConfig\n",
    "\n",
    "# # 1. Define the 4-bit configuration\n",
    "# bnb_config = BitsAndBytesConfig(\n",
    "#     load_in_4bit=True,\n",
    "#     bnb_4bit_quant_type=\"nf4\",      # Normalized Float 4 (recommended for accuracy)\n",
    "#     bnb_4bit_compute_dtype=torch.bfloat16, # Compute in float16 or bfloat16\n",
    "#     bnb_4bit_use_double_quant=True, # Double quantization to save even more memory\n",
    "# )\n",
    "\n",
    "model_id = \"CohereLabs/aya-101\"\n",
    "\n",
    "# 2. Load the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "# 3. Load the model with the 4-bit config\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "    model_id,\n",
    "    # quantization_config=bnb_config,\n",
    "\ttorch_dtype=torch.bfloat16,\n",
    "    device_map=\"cuda\", # Automatically distributes layers to GPU\n",
    "    cache_dir=os.getenv(\"HF_CACHE_DIR\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c04aa3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(250112, 4096)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(250112, 4096)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 64)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=4096, out_features=10240, bias=False)\n",
       "              (wi_1): Linear(in_features=4096, out_features=10240, bias=False)\n",
       "              (wo): Linear(in_features=10240, out_features=4096, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-23): 23 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=4096, out_features=10240, bias=False)\n",
       "              (wi_1): Linear(in_features=4096, out_features=10240, bias=False)\n",
       "              (wo): Linear(in_features=10240, out_features=4096, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(250112, 4096)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 64)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=4096, out_features=10240, bias=False)\n",
       "              (wi_1): Linear(in_features=4096, out_features=10240, bias=False)\n",
       "              (wo): Linear(in_features=10240, out_features=4096, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-23): 23 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=4096, out_features=10240, bias=False)\n",
       "              (wi_1): Linear(in_features=4096, out_features=10240, bias=False)\n",
       "              (wo): Linear(in_features=10240, out_features=4096, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=250112, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a2b9d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_lang = 'no_prompt'\n",
    "is_base_model = True\n",
    "data_split = 'dev'\n",
    "sample_size = 5\n",
    "output_dir = 'output_temp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ecfab7f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load model: CohereLabs/aya-101\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54ce798127c24c5ab510f48f58e2772c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9381ca777294bdda47a60afdae88ae2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/224 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d37b733095b44ff6a99dc619de4ed896",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/218 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing activation for next token prediction task (ind_Latn): 100%|██████████| 5/5 [00:01<00:00,  3.75it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c108094c22524123b3638ef27192b9ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/224 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0967aff2ca4b4b47952478a20abbc98c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/218 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing activation for next token prediction task (eng_Latn): 100%|██████████| 5/5 [00:00<00:00,  6.64it/s]\n"
     ]
    }
   ],
   "source": [
    "# Load Model\n",
    "print(f'Load model: {model_name}')\n",
    "\n",
    "if prompt_lang == 'all':\n",
    "\tprompt_id_saver = 'prompted'\n",
    "elif prompt_lang == 'no_prompt':\n",
    "\tprompt_id_saver = 'raw'\n",
    "else:\n",
    "\tprompt_id_saver = f'prompt_{prompt_lang}' \n",
    "\n",
    "saver = GeneralActivationSaver(output_dir, task_id='next_token', data_split=data_split, model_name=model_name, prompt_id=prompt_id_saver)\n",
    "\n",
    "if 'aya-101' in model_name.lower():\n",
    "\thooked_model = T5HookedModel(model_name, saver=saver)\n",
    "else:\n",
    "\traise ValueError(f\"Model {model_name} not supported in this script.\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "languages = ['ind_Latn', 'eng_Latn']\n",
    "\n",
    "# Feed Forward\n",
    "# for lang in languages:\n",
    "for lang in languages:\n",
    "\t\n",
    "\t# Load Dataset\n",
    "\tdatasets_per_lang = {}\n",
    "\tif data_split == 'all':\n",
    "\t\tdatasets_per_lang_temp = {}\n",
    "\t\tdatasets_per_lang_temp[lang] = load_dataset(\"openlanguagedata/flores_plus\", lang, cache_dir=os.getenv(\"HF_CACHE_DIR\"))\n",
    "\t\tdatasets_per_lang[lang] = concatenate_datasets([datasets_per_lang_temp[lang]['dev'], datasets_per_lang_temp[lang]['devtest']])\n",
    "\telse:\n",
    "\t\tdatasets_per_lang[lang] = load_dataset(\"openlanguagedata/flores_plus\", lang, split=data_split, cache_dir=os.getenv(\"HF_CACHE_DIR\"))\n",
    "\t\n",
    "\t# Sample Dataset\n",
    "\tif sample_size:\n",
    "\t\tdatasets_per_lang[lang] = datasets_per_lang[lang].shuffle(seed=42).select(range(sample_size))\n",
    "\n",
    "\t# Load Prompt Template\n",
    "\tif prompt_lang == \"all\": \n",
    "\t\twith open(f'./prompts/next_token/{lang}.txt') as f:\n",
    "\t\t\tprompt_template = f.read()\n",
    "\telse:\n",
    "\t\twith open(f'./prompts/next_token/{prompt_lang}.txt') as f:\n",
    "\t\t\tprompt_template = f.read()\n",
    "\t\n",
    "\t# Iterate Through Each Instance\n",
    "\tfor instance in tqdm(datasets_per_lang[lang], desc=f\"Processing activation for next token prediction task ({lang})\"):\n",
    "\t\t# Set ID and Language in Saver\n",
    "\t\thooked_model.set_saver_id(str(instance['id']))\n",
    "\t\thooked_model.set_saver_lang(lang)\n",
    "\n",
    "\t\t# Check if activations already exist\n",
    "\t\tif saver.check_exists():\n",
    "\t\t\tprint(f\"Activations already exist for ID {instance['id']} in language {lang}. Skipping...\")\n",
    "\t\t\tcontinue\n",
    "\n",
    "\t\t# Build Prompt Based on Template\n",
    "\t\tprompt = prompt_template.replace(\"{text}\", instance['text'])\n",
    "\n",
    "\t\t# Inference\n",
    "\t\tif is_base_model or 'bloom' in model_name:\n",
    "\t\t\ttext = prompt\n",
    "\t\telse:\n",
    "\t\t\t\n",
    "\t\t\t# Gemma2 does not support system message\n",
    "\t\t\tif 'google/gemma-2' in model_name.lower():\n",
    "\t\t\t\tmessages = [\n",
    "\t\t\t\t\t{'role': 'user', 'content': prompt}\n",
    "\t\t\t\t]\n",
    "\t\t\telse:\n",
    "\t\t\t\tmessages = [\n",
    "\t\t\t\t\t{'role': 'system', 'content': ''},\n",
    "\t\t\t\t\t{'role': 'user', 'content': prompt}\n",
    "\t\t\t\t]\n",
    "\n",
    "\t\t\tif 'meta-llama' in model_name.lower():\n",
    "\t\t\t\tuser_prompt = messages[-1]['content']\n",
    "\t\t\t\ttext = f\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\n<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\n{user_prompt}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\n",
    "\t\t\telse:\n",
    "\t\t\t\ttext = tokenizer.apply_chat_template(\n",
    "\t\t\t\t\tmessages,\n",
    "\t\t\t\t\ttokenize=False,\n",
    "\t\t\t\t\tadd_generation_prompt=True,\n",
    "\t\t\t\t\tenable_thinking=False \n",
    "\t\t\t\t)\n",
    "\t\t\n",
    "\t\tinputs = tokenizer([text], return_tensors=\"pt\").to(hooked_model.model.device)\n",
    "\t\t_ = hooked_model.generate(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be4f56a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "activation-extraction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
