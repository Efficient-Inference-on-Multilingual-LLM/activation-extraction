{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51d7e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "login(\"YOUR_HF_TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d81860",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce0e8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "data = {}\n",
    "data['Javanese'] = load_dataset(\"openlanguagedata/flores_plus\", \"jav_Latn\", cache_dir='./huggingface/flores')\n",
    "data['Sundanese'] = load_dataset(\"openlanguagedata/flores_plus\", \"sun_Latn\", cache_dir='./huggingface/flores')\n",
    "data['Welsh'] = load_dataset(\"openlanguagedata/flores_plus\", \"cym_Latn\", cache_dir='./huggingface/flores')\n",
    "data['Turkish'] = load_dataset(\"openlanguagedata/flores_plus\", \"tur_Latn\", cache_dir='./huggingface/flores')\n",
    "data['French'] = load_dataset(\"openlanguagedata/flores_plus\", \"fra_Latn\", cache_dir='./huggingface/flores')\n",
    "data['English'] = load_dataset(\"openlanguagedata/flores_plus\", \"eng_Latn\", cache_dir='./huggingface/flores')\n",
    "data['Indonesian'] = load_dataset(\"openlanguagedata/flores_plus\", \"ind_Latn\", cache_dir='./huggingface/flores')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f6f123c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def convert_to_dataframe(data):\n",
    "    train_df = data['dev'].to_pandas()\n",
    "    val_df = data['devtest'].to_pandas()\n",
    "\n",
    "    full_df = pd.concat([train_df, val_df], ignore_index=True)\n",
    "    return full_df\n",
    "\n",
    "for key in data.keys():\n",
    "    data[key] = convert_to_dataframe(data[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e37d146c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "You are a professional translator. \n",
    "Translate the following sentence from {src_lang} into {tgt_lang}.\n",
    "\n",
    "Sentence:\n",
    "\"{src_sentence}\"\n",
    "\n",
    "Only output the translation, nothing else.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1426e458",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "from transformers import AutoModelForCausalLM, AutoProcessor\n",
    "\n",
    "folder_name = \"Qwen/Qwen3-8B\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    folder_name,\n",
    "    cache_dir=f\"./huggingface/{folder_name}\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    trust_remote_code=True\n",
    ").to('mps')\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(\n",
    "    folder_name,\n",
    "    cache_dir=f\"./huggingface/{folder_name}\",\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "def hook_fn(m, i, o, layer_id):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    save_path = os.path.join(save_dir, f\"{layer_id}.pt\")\n",
    "    torch.save(o[0][-1, :].detach().cpu(), save_path)\n",
    "\n",
    "for i, layer in enumerate(model.model.layers):\n",
    "    layer.register_forward_hook(\n",
    "        lambda m, i, o, layer_id=i: hook_fn(m, i, o, layer_id=layer_id)\n",
    "    )\n",
    "\n",
    "languages=[\"English\", \"French\", \"Indonesian\", \"Javanese\", \"Sundanese\", \"Welsh\", \"Turkish\"]\n",
    "\n",
    "for source_language in languages:\n",
    "    for target_language in languages:\n",
    "        if source_language != target_language:\n",
    "            for _, row in data[source_language][:50].iterrows():\n",
    "                text_id = str(row['id'])\n",
    "\n",
    "                save_dir = f\"./activations/flores/{folder_name}/{source_language}/{target_language}/{text_id}/\"\n",
    "\n",
    "                inputs = processor(\n",
    "                    text=prompt_template.format(\n",
    "                        src_lang=source_language,\n",
    "                        tgt_lang=target_language,\n",
    "                        src_sentence=row['text']\n",
    "                    ),\n",
    "                    return_tensors=\"pt\"\n",
    "                )\n",
    "\n",
    "                inputs = {k: v.to(\"mps\") for k, v in inputs.items()}\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    outputs = model(**inputs)\n",
    "                    print(text_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc49fe09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Language to Multilingual\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.manifold import TSNE\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "models = [{'name': 'meta-llama/Llama-3.2-1B', 'layers': 16}, {'name': 'google/gemma-3-1b-pt', 'layers': 25}]\n",
    "languages=[\"English\", \"French\", \"Indonesian\", \"Javanese\", \"Sundanese\", \"Welsh\", \"Turkish\"]\n",
    "\n",
    "cmap = plt.get_cmap('tab10')\n",
    "color_map = {language: cmap(i) for i, language in enumerate(languages)}\n",
    "\n",
    "for model_id in range (len(models)):\n",
    "    for source_language in languages:\n",
    "        if (model_id == 0):\n",
    "            fig, axes = plt.subplots(int(models[model_id]['layers']/8), 8, figsize=(32, int(models[model_id]['layers']/2)))\n",
    "            axes = axes.flatten()  \n",
    "        else:\n",
    "            fig, axes = plt.subplots(5, 5, figsize=(20, 20))\n",
    "            axes = axes.flatten()  \n",
    "\n",
    "        for layer in range(models[model_id]['layers']):\n",
    "            label_language = []\n",
    "            latent = []\n",
    "\n",
    "            for target_language in languages:\n",
    "                if (target_language != source_language):\n",
    "                    base_path = f\"./activations/flores/{models[model_id]['name']}/{source_language}/{target_language}/\"\n",
    "                    for text_id in os.listdir(base_path):\n",
    "                        text_path = os.path.join(base_path, text_id)\n",
    "                        if not os.path.isdir(text_path):\n",
    "                            continue\n",
    "                        path = os.path.join(text_path, f\"{layer}.pt\")\n",
    "                        activation_values = torch.load(path)\n",
    "                        if (model_id == 0):\n",
    "                            latent.append(activation_values.to(torch.float32).numpy())\n",
    "                        else:\n",
    "                            latent.append(activation_values[-1, :].to(torch.float32).numpy())\n",
    "                        label_language.append(target_language)\n",
    "\n",
    "            latent = np.array(latent)\n",
    "            tsne = TSNE(n_components=2, random_state=42)\n",
    "            latent_2d = tsne.fit_transform(latent)\n",
    "\n",
    "            ax = axes[layer]\n",
    "            for lang in languages:\n",
    "                indices = [i for i, lbl in enumerate(label_language) if lbl == lang]\n",
    "                ax.scatter(latent_2d[indices, 0], latent_2d[indices, 1],\n",
    "                        label=lang, color=color_map[lang], alpha=0.6, s=10)\n",
    "\n",
    "            ax.set_title(f\"Layer {layer}\", fontsize=10)\n",
    "\n",
    "        legend_elements = [Line2D([0], [0], marker='o', color='w',\n",
    "                            label=lang, markerfacecolor=color_map[lang],\n",
    "                            markersize=8, alpha=0.6) for lang in languages]\n",
    "        plt.tight_layout(rect=[0, 0, 1, 0.90]) \n",
    "        fig.legend(handles=legend_elements,\n",
    "                loc='upper center', bbox_to_anchor=(0.5, 0.96),\n",
    "                ncol=len(languages), title='Languages')\n",
    "        plt.suptitle(f'{models[model_id]['name']} MT Source Language {source_language}')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2acee785",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Language to Multilingual\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.manifold import TSNE\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "models = [{'name': 'meta-llama/Llama-3.2-1B', 'layers': 16}, {'name': 'google/gemma-3-1b-pt', 'layers': 25}]\n",
    "languages=[\"English\", \"French\", \"Indonesian\", \"Javanese\", \"Sundanese\", \"Welsh\", \"Turkish\"]\n",
    "\n",
    "cmap = plt.get_cmap('tab10')\n",
    "color_map = {language: cmap(i) for i, language in enumerate(languages)}\n",
    "\n",
    "for model_id in range (len(models)):\n",
    "    for target_language in languages:\n",
    "        if (model_id == 0):\n",
    "            fig, axes = plt.subplots(int(models[model_id]['layers']/8), 8, figsize=(32, int(models[model_id]['layers']/2)))\n",
    "            axes = axes.flatten()  \n",
    "        else:\n",
    "            fig, axes = plt.subplots(5, 5, figsize=(20, 20))\n",
    "            axes = axes.flatten()  \n",
    "\n",
    "        for layer in range(models[model_id]['layers']):\n",
    "            label_language = []\n",
    "            latent = []\n",
    "\n",
    "            for source_language in languages:\n",
    "                if (target_language != source_language):\n",
    "                    base_path = f\"./activations/flores/{models[model_id]['name']}/{source_language}/{target_language}/\"\n",
    "                    for text_id in os.listdir(base_path):\n",
    "                        text_path = os.path.join(base_path, text_id)\n",
    "                        if not os.path.isdir(text_path):\n",
    "                            continue\n",
    "                        path = os.path.join(text_path, f\"{layer}.pt\")\n",
    "                        activation_values = torch.load(path)\n",
    "                        if (model_id == 0):\n",
    "                            latent.append(activation_values.to(torch.float32).numpy())\n",
    "                        else:\n",
    "                            latent.append(activation_values[-1, :].to(torch.float32).numpy())\n",
    "                        label_language.append(source_language)\n",
    "\n",
    "            latent = np.array(latent)\n",
    "            tsne = TSNE(n_components=2, random_state=42)\n",
    "            latent_2d = tsne.fit_transform(latent)\n",
    "\n",
    "            ax = axes[layer]\n",
    "            for lang in languages:\n",
    "                indices = [i for i, lbl in enumerate(label_language) if lbl == lang]\n",
    "                ax.scatter(latent_2d[indices, 0], latent_2d[indices, 1],\n",
    "                        label=lang, color=color_map[lang], alpha=0.6, s=10)\n",
    "\n",
    "            ax.set_title(f\"Layer {layer}\", fontsize=10)\n",
    "\n",
    "        legend_elements = [Line2D([0], [0], marker='o', color='w',\n",
    "                            label=lang, markerfacecolor=color_map[lang],\n",
    "                            markersize=8, alpha=0.6) for lang in languages]\n",
    "        plt.tight_layout(rect=[0, 0, 1, 0.90]) \n",
    "        fig.legend(handles=legend_elements,\n",
    "                loc='upper center', bbox_to_anchor=(0.5, 0.96),\n",
    "                ncol=len(languages), title='Source Languages')\n",
    "        plt.suptitle(f'{models[model_id]['name']} MT Target Language {target_language}')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bae0e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Language to Multilingual\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.manifold import TSNE\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "models = [{'name': 'meta-llama/Llama-3.2-1B', 'layers': 16}, {'name': 'google/gemma-3-1b-pt', 'layers': 25}]\n",
    "languages=[\"English\", \"French\", \"Indonesian\", \"Javanese\", \"Sundanese\", \"Welsh\", \"Turkish\"]\n",
    "\n",
    "cmap = plt.get_cmap('tab10')\n",
    "color_map = {language: cmap(i) for i, language in enumerate(languages)}\n",
    "\n",
    "for model_id in range (len(models)):\n",
    "    for language in languages:\n",
    "        if (model_id == 0):\n",
    "            fig, axes = plt.subplots(int(models[model_id]['layers']/8), 8, figsize=(32, int(models[model_id]['layers']/2)))\n",
    "            axes = axes.flatten()  \n",
    "        else:\n",
    "            fig, axes = plt.subplots(5, 5, figsize=(20, 20))\n",
    "            axes = axes.flatten()  \n",
    "\n",
    "        for layer in range(models[model_id]['layers']):\n",
    "            label_language = []\n",
    "            latent = []\n",
    "\n",
    "            target_language = language\n",
    "            for source_language in languages:\n",
    "                if (target_language != source_language):\n",
    "                    base_path = f\"./activations/flores/{models[model_id]['name']}/{source_language}/{target_language}/\"\n",
    "                    for text_id in os.listdir(base_path):\n",
    "                        text_path = os.path.join(base_path, text_id)\n",
    "                        if not os.path.isdir(text_path):\n",
    "                            continue\n",
    "                        path = os.path.join(text_path, f\"{layer}.pt\")\n",
    "                        activation_values = torch.load(path)\n",
    "                        if (model_id == 0):\n",
    "                            latent.append(activation_values.to(torch.float32).numpy())\n",
    "                        else:\n",
    "                            latent.append(activation_values[-1, :].to(torch.float32).numpy())\n",
    "                        label_language.append(source_language)\n",
    "\n",
    "            source_language = language\n",
    "            for target_language in languages:\n",
    "                if (target_language != source_language):\n",
    "                    base_path = f\"./activations/flores/{models[model_id]['name']}/{source_language}/{target_language}/\"\n",
    "                    for text_id in os.listdir(base_path):\n",
    "                        text_path = os.path.join(base_path, text_id)\n",
    "                        if not os.path.isdir(text_path):\n",
    "                            continue\n",
    "                        path = os.path.join(text_path, f\"{layer}.pt\")\n",
    "                        activation_values = torch.load(path)\n",
    "                        if (model_id == 0):\n",
    "                            latent.append(activation_values.to(torch.float32).numpy())\n",
    "                        else:\n",
    "                            latent.append(activation_values[-1, :].to(torch.float32).numpy())\n",
    "                        label_language.append(target_language)\n",
    "\n",
    "            latent = np.array(latent)\n",
    "            tsne = TSNE(n_components=2, random_state=42)\n",
    "            latent_2d = tsne.fit_transform(latent)\n",
    "\n",
    "            ax = axes[layer]\n",
    "            for lang in languages:\n",
    "                indices = [i for i, lbl in enumerate(label_language) if lbl == lang]\n",
    "                ax.scatter(latent_2d[indices, 0], latent_2d[indices, 1],\n",
    "                        label=lang, color=color_map[lang], alpha=0.6, s=10)\n",
    "\n",
    "            ax.set_title(f\"Layer {layer}\", fontsize=10)\n",
    "\n",
    "        legend_elements = [Line2D([0], [0], marker='o', color='w',\n",
    "                            label=lang, markerfacecolor=color_map[lang],\n",
    "                            markersize=8, alpha=0.6) for lang in languages]\n",
    "        plt.tight_layout(rect=[0, 0, 1, 0.90]) \n",
    "        fig.legend(handles=legend_elements,\n",
    "                loc='upper center', bbox_to_anchor=(0.5, 0.96),\n",
    "                ncol=len(languages), title='Languages')\n",
    "        plt.suptitle(f'{models[model_id]['name']} MT Language {language}')\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
